{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNG5MK4qcDAf6GAkfdUi3Os"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Compilador de datos de la evaluación de la lectura mensual"
      ],
      "metadata": {
        "id": "C65Wb78VRwsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abriendo cuestiones de python"
      ],
      "metadata": {
        "id": "fjTdft7Oau8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gspread\n",
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import gspread\n",
        "from google.auth import default\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "auth.authenticate_user()\n",
        "creds, _ = default() # default pertenece a google.auth. Genera una tupla, y solo nos importa el primer elemento.\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "rkkgnt5ta1aJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ceb37e-0d92-4f7a-a928-b6ddeeda6415"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from gspread) (2.27.1)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from gspread) (2.17.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.2.1->gspread) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.2.1->gspread) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.2.1->gspread) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.2.1->gspread) (3.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->gspread) (0.5.0)\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compilar datos"
      ],
      "metadata": {
        "id": "ql6wwVb3MPTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parte de la base madre:\n",
        "\n",
        "bs_madre_lm = gc.open('Links datos lectura mensual asesorados 2023').sheet1 # Acá defino la hoja que quiero abrir\n",
        "bs_madre_lm = bs_madre_lm.get_all_values() #get_all_values gives a list of rows\n",
        "bs_madre_lm = pd.DataFrame(bs_madre_lm,) #Convert to a DataFrame\n",
        "bs_madre_lm.columns = bs_madre_lm.iloc[0]\n",
        "bs_madre_lm = bs_madre_lm[1:]\n",
        "bs_madre_lm = bs_madre_lm.iloc[:,0:5]\n",
        "bs_madre_lm[\"nombre_arch\"] = \"Planilla registro lecturas mensuales \" + bs_madre_lm.Colegio + \" \" + bs_madre_lm.Año\n",
        "bs_madre_lm = bs_madre_lm.loc[bs_madre_lm.Año == \"2023\"] # Se puede modificar o agregar un filtro en la base madre\n",
        "\n",
        "lista_datos_reales = [] # Guardar combinaciones de colegios y cursos que sí existen\n",
        "lista_compilados = []\n",
        "\n",
        "for n in range(len(bs_madre_lm.nombre_arch.to_list())):\n",
        "  try:\n",
        "    archivo = bs_madre_lm.nombre_arch.to_list()[n]\n",
        "    Colegio = bs_madre_lm.Colegio.to_list()[n]\n",
        "    Año = bs_madre_lm.Año.to_list()[n]\n",
        "    hojas = gc.open(archivo)\n",
        "    num_hojas = len(hojas.worksheets()) # Obtener el número de hojas en el archivo\n",
        "    nombres_hojas = [hojas.get_worksheet(i).title for i in range(num_hojas)] # Obtener los nombres de las hojas en el archivo\n",
        "    nombres_hojas = [hoja for hoja in nombres_hojas if hoja in [\"1A\",\"1B\",\"1C\",\"1D\",\"1E\"]]\n",
        "    for hoja in  nombres_hojas:\n",
        "      rows = hojas.worksheet(hoja)\n",
        "      rows = rows.get_all_values()[6:53]\n",
        "      rows = [fila[:13] for fila in rows]\n",
        "      df = pd.DataFrame(rows)\n",
        "      df.columns = df.iloc[0]\n",
        "      df = df[1:]\n",
        "      df.columns = [\"N\",\"Nombre\",\"Lectura_1\",\"Lectura_2\",\"Lectura_3\",\"Lectura_4\",\"Lectura_5\",\n",
        "                    \"Lectura_6\",\"Lectura_7\",\"Lectura_8\",\"Lectura_9\",\"Cantidad_palabras\",\n",
        "                    \"Final\"]\n",
        "      df[\"Año\"] = Año\n",
        "      df[\"Colegio\"] = Colegio\n",
        "      df[\"Letra\"] = hoja\n",
        "      lista_compilados.append(df)\n",
        "      lista_datos_reales.append(Año + \"_\" + Colegio + \"_\" + hoja)\n",
        "      print(\"planilla \" + archivo + \" \" + hoja + \" correctamente compilada\")\n",
        "  except:\n",
        "    print(\"error en \"+archivo)\n",
        "\n",
        "compilado_lm = pd.concat(lista_compilados, ignore_index=True)\n",
        "\n",
        "# Si se quisiera revisar alguna base:\n",
        "#rows = gc.open(i).sheet1\n",
        "#rows = rows.get_all_values()[6:53]\n",
        "#rows = [fila[:13] for fila in rows]\n",
        "\n"
      ],
      "metadata": {
        "id": "4bJxLaiDavEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compilado_lm # solo para ver si hay problemas en la base"
      ],
      "metadata": {
        "id": "aHUktIbJDKBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with pd.ExcelWriter(\"Compilados lectura.xlsx\") as writer:\n",
        "    # compilado_lm.to_excel(writer, sheet_name=\"compilado\", index=False)"
      ],
      "metadata": {
        "id": "kg_i5mGdWwdX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# depurar compilado:\n",
        "## Borrar los valores faltantes de los nombres:\n",
        "compilado_lm[\"Nombre\"] = compilado_lm[\"Nombre\"].replace('', np.nan)\n",
        "compilado_lm.dropna(subset=\"Nombre\",inplace=True)\n",
        "## Resetear el índice\n",
        "compilado_lm = compilado_lm.reset_index(drop=True)\n",
        "## Seleccionar columnas:\n",
        "compilado_lm = compilado_lm.iloc[:,0:16]\n",
        "## Cambiar nombres:\n",
        "compilado_lm.columns = [\"N\",\"Nombre\",\"Lectura_1\",\"Lectura_2\",\"Lectura_3\",\"Lectura_4\",\"Lectura_5\",\"Lectura_6\",\"Lectura_7\",\"Lectura_8\",\"Lectura_9\",\"Cantidad_palabras\",\"Final\",\"Año\",\"Colegio\",\"Letra\"]\n",
        "compilado_lm = compilado_lm.iloc[:,[13,14,15,0,1,2,3,4,5,6,7,8,9,10,11,12]]\n"
      ],
      "metadata": {
        "id": "AQvLF8YDRxRv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " compilado_lm # solo para ver la versión depurada"
      ],
      "metadata": {
        "id": "u46TSmxgWANJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "# Ahora vamos a hacer bases resumen en base a los presentes\n",
        "## Hacer formato long\n",
        "compilado_lm_long = compilado_lm.melt(id_vars = [\"N\",\"Año\",\"Colegio\",\"Letra\",\"Nombre\"], value_vars=[\"Lectura_1\",\"Lectura_2\",\"Lectura_3\",\"Lectura_4\",\n",
        "                                                \"Lectura_5\",\"Lectura_6\",\"Lectura_7\",\"Lectura_8\",\n",
        "                                                \"Lectura_9\",\"Cantidad_palabras\",\"Final\"], var_name='Lectura', value_name='Categoría')\n",
        "# Reemplazar valores ''\n",
        "compilado_lm_long[\"Categoría\"] = compilado_lm_long[\"Categoría\"].replace('', \"Ausente\")\n",
        "\n",
        "base_resumen = compilado_lm_long.groupby(['Año','Colegio', 'Letra', 'Lectura', 'Categoría'])['Categoría'].count().reset_index(name='Frecuencia')\n",
        "base_resumen[\"Porcentaje\"] = base_resumen.groupby(['Año','Colegio', 'Letra', 'Lectura'])[\"Frecuencia\"].apply(lambda x: 100 * x / float(x.sum()))\n",
        "base_resumen[\"Porcentaje\"] = np.round(base_resumen[\"Porcentaje\"],2)\n",
        "orden_categorias = ['E', 'MB', 'B', 'S', 'I', 'NL', 'Ausente']\n",
        "base_resumen['Categoría'] = pd.Categorical(base_resumen['Categoría'], categories=orden_categorias, ordered=True)\n",
        "base_resumen = base_resumen.sort_values(['Año', 'Colegio', 'Letra', 'Lectura', 'Categoría'])\n",
        "\n",
        "\n",
        "# Eliminar ausentes\n",
        "compilado_lm_long = compilado_lm_long[np.logical_and(compilado_lm_long[\"Categoría\"] != \"Ausente\", ~compilado_lm_long[\"Categoría\"].isna())]\n",
        "\n",
        "\n",
        "# Contar cada categoría\n",
        "frecuencia = compilado_lm_long.groupby(['Año','Colegio', 'Letra', 'Lectura', 'Categoría'])['Categoría'].count().reset_index(name='Frecuencia')\n",
        "# Generar grid:\n",
        "Año = compilado_lm_long[\"Año\"].unique()\n",
        "Colegio = compilado_lm_long[\"Colegio\"].unique()\n",
        "Letra = compilado_lm_long[\"Letra\"].unique()\n",
        "Lectura = compilado_lm_long[\"Lectura\"].unique()\n",
        "Categoría = ['E', 'MB', 'B', 'S', 'I', \"NL\"]\n",
        "df_completo = pd.DataFrame(list(product(Año, Colegio, Letra, Lectura, Categoría)), columns=[\"Año\", \"Colegio\", \"Letra\", \"Lectura\", \"Categoría\"])\n",
        "# Hacer el left join:\n",
        "frecuencia_completa = pd.merge(df_completo, frecuencia, on=['Año', 'Colegio', 'Letra', \"Lectura\", 'Categoría'], how='left')\n",
        "frecuencia_completa[\"Frecuencia\"] = frecuencia_completa[\"Frecuencia\"].fillna(0)\n",
        "frecuencia_completa[\"Porcentaje_frecuencia\"] = frecuencia_completa.groupby(['Año','Colegio', 'Letra', 'Lectura'])[\"Frecuencia\"].apply(lambda x: 100 * x / float(x.sum()))\n",
        "frecuencia_completa[\"Porcentaje_frecuencia\"] = frecuencia_completa[\"Porcentaje_frecuencia\"].round(2)\n",
        "\n",
        "orden_categorias = ['E', 'MB', 'B', 'S', 'I', 'NL']\n",
        "frecuencia_completa['Categoría'] = pd.Categorical(frecuencia_completa['Categoría'], categories=orden_categorias, ordered=True)\n",
        "frecuencia_completa = frecuencia_completa.sort_values(['Año', 'Colegio', 'Letra', 'Lectura', 'Categoría'])\n",
        "frecuencia_completa[\"Porcentaje_frecuencia\"] = frecuencia_completa[\"Porcentaje_frecuencia\"].fillna(0)\n",
        "\n",
        "frecuencia_completa[\"ID\"] = frecuencia_completa[\"Año\"] + \"_\" + frecuencia_completa[\"Colegio\"] + \"_\" + frecuencia_completa[\"Letra\"]\n",
        "\n",
        "frecuencia_completa = frecuencia_completa[frecuencia_completa[\"ID\"].isin(lista_datos_reales)]\n",
        "\n",
        "frecuencia_completa = frecuencia_completa.drop(\"ID\", axis = 1)\n"
      ],
      "metadata": {
        "id": "nDdpvJkV1j0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabla_porcentajes = frecuencia_completa.pivot_table(index=['Año', 'Colegio', 'Letra',  'Categoría'], \n",
        "                                               columns='Lectura', \n",
        "                                               values='Porcentaje_frecuencia')\n",
        "# resetear índice\n",
        "# tabla_porcentajes.pop(\"Categoría\")\n",
        "tabla_porcentajes = tabla_porcentajes.reset_index()\n",
        "\n",
        "tabla_frecuencias = frecuencia_completa.pivot_table(index=['Año', 'Colegio', 'Letra',  'Categoría'], \n",
        "                                               columns='Lectura', \n",
        "                                               values='Frecuencia')\n",
        "# resetear índice\n",
        "# tabla_frecuencias.pop(\"Categoría\")\n",
        "tabla_frecuencias = tabla_frecuencias.reset_index()\n"
      ],
      "metadata": {
        "id": "qlt1pj_xWI-I"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.ExcelWriter(\"Compilados lectura mensual.xlsx\") as writer:\n",
        "   \n",
        "    # use to_excel function and specify the sheet_name and index\n",
        "    # to store the dataframe in specified sheet\n",
        "    compilado_lm.to_excel(writer, sheet_name=\"compilado\", index=False)\n",
        "    base_resumen.to_excel(writer, sheet_name=\"resumen general\", index=False)\n",
        "    tabla_porcentajes.to_excel(writer, sheet_name=\"porcentajes\", index=False)\n",
        "    tabla_frecuencias.to_excel(writer, sheet_name=\"frecuencias\", index=False)"
      ],
      "metadata": {
        "id": "Dr7FwQqbO2Kb"
      },
      "execution_count": 60,
      "outputs": []
    }
  ]
}